import torch
import sys
import os
import io

# D√©sactiver les sorties verboses
os.environ['TQDM_DISABLE'] = '1'

sys.path.append('./Tokenizer')
sys.path.append('./Model')

from Tokenizer import MYBPE
from gpt2_model import GPT2Model

def silent_operation(func, *args, **kwargs):
    """Ex√©cute une fonction sans afficher les logs"""
    old_stdout = sys.stdout
    sys.stdout = io.StringIO()
    try:
        result = func(*args, **kwargs)
    finally:
        sys.stdout = old_stdout
    return result

print("\n" + "="*60)
print("üéÆ GPT-2 - MODE INTERACTIF")
print("="*60)

# Charger le tokenizer (silencieux)
print("\nüì¶ Chargement...")
tokenizer = MYBPE(vocab_size=300)
tokenizer.load_tokenizer("Tokenizer/tokenizer_model.bin")

# Charger le mod√®le
model = GPT2Model(
    vocab_size=300,
    embed_dim=256,
    num_heads=8,
    num_layers=6,
    max_seq_len=64
)
model.load_state_dict(torch.load('./checkpoints/final_model.pt'))
model.eval()

print("‚úÖ Mod√®le pr√™t (~1M param√®tres)\n")

print("="*60)
print("üí¨ MODE INTERACTIF")
print("="*60)
print("\nüí° Conseils:")
print("  ‚Ä¢ Temperature 0.5 = coh√©rent mais r√©p√©titif")
print("  ‚Ä¢ Temperature 0.8 = √©quilibr√© (recommand√©)")
print("  ‚Ä¢ Temperature 1.5 = cr√©atif mais chaotique")
print("\n  Tapez 'quit' pour quitter\n")

while True:
    print("-"*60)
    prompt = input("üìù Votre prompt: ")
    
    if prompt.lower() in ['quit', 'exit', 'q']:
        print("\nüëã Au revoir!\n")
        break
    
    if not prompt.strip():
        print("‚ö†Ô∏è  Prompt vide!\n")
        continue
    
    try:
        # Param√®tres
        try:
            temp_input = input("üå°Ô∏è  Temperature (appuyez Entr√©e pour 0.8): ")
            temp = float(temp_input) if temp_input.strip() else 0.8
            
            tokens_input = input("üìè Nombre de tokens (appuyez Entr√©e pour 50): ")
            max_tokens = int(tokens_input) if tokens_input.strip() else 50
        except:
            temp = 0.8
            max_tokens = 50
        
        print(f"\n‚è≥ G√©n√©ration en cours...")
        
        # Encoder (silencieux)
        tokens = silent_operation(tokenizer.encoder, prompt)
        input_ids = torch.tensor([tokens])
        
        # G√©n√©rer (silencieux)
        generated = silent_operation(
            model.generate,
            input_ids,
            max_new_tokens=max_tokens,
            temperature=temp,
            top_k=40
        )
        
        # D√©coder (silencieux)
        text = silent_operation(tokenizer.decoder, generated[0].tolist())
        
        # Afficher le r√©sultat
        print("\n" + "="*60)
        print("‚ú® R√âSULTAT:")
        print("="*60)
        print(text)
        print("="*60 + "\n")
        
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}\n")

print("="*60)
print("‚úÖ Session termin√©e!")
print("="*60 + "\n")